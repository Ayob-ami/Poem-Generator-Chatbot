{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-18T01:00:29.684296Z\",\"iopub.execute_input\":\"2024-12-18T01:00:29.685449Z\",\"iopub.status.idle\":\"2024-12-18T01:00:30.657693Z\",\"shell.execute_reply.started\":\"2024-12-18T01:00:29.685420Z\",\"shell.execute_reply\":\"2024-12-18T01:00:30.656657Z\"}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-20T13:00:27.695987Z\",\"iopub.execute_input\":\"2024-12-20T13:00:27.696914Z\",\"iopub.status.idle\":\"2024-12-20T13:00:42.851218Z\",\"shell.execute_reply.started\":\"2024-12-20T13:00:27.696874Z\",\"shell.execute_reply\":\"2024-12-20T13:00:42.850368Z\"}}\n!pip install transformers fastapi gradio uvicorn\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-20T12:56:25.928197Z\",\"iopub.execute_input\":\"2024-12-20T12:56:25.928858Z\",\"iopub.status.idle\":\"2024-12-20T13:00:06.533130Z\",\"shell.execute_reply.started\":\"2024-12-20T12:56:25.928822Z\",\"shell.execute_reply\":\"2024-12-20T13:00:06.532150Z\"}}\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Load model and tokenizer\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"microsoft/phi-3-mini-4k-instruct\",\n    device_map=\"cuda\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True\n)\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-3-mini-4k-instruct\")\n\n# Test generation\nprompt = \"Compose a captivating poem in 8-9 lines about the beauty of structured poetry. Begin with a vivid image to draw the reader in, explore emotions and metaphors in the middle, and end with a resonant and thought-provoking conclusion. Use poetic devices like rhyme, alliteration, and rhythm to enhance the flow and make the poem memorable.\"\n# Tokenize the input\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\noutputs = model.generate(input_ids=input_ids, max_new_tokens=300, max_length=100, temperature=0.8)\npoem = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(poem)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-20T13:21:41.328638Z\",\"iopub.execute_input\":\"2024-12-20T13:21:41.329062Z\",\"iopub.status.idle\":\"2024-12-20T13:21:51.115179Z\",\"shell.execute_reply.started\":\"2024-12-20T13:21:41.329027Z\",\"shell.execute_reply\":\"2024-12-20T13:21:51.114243Z\"}}\nimport gradio as gr\nfrom transformers import pipeline\n\n# Load model and tokenizer using pipeline for more efficient memory management\npipe = pipeline(\n    \"text-generation\",\n    model=\"microsoft/phi-3-mini-4k-instruct\",\n    tokenizer=\"microsoft/phi-3-mini-4k-instruct\",\n    device_map=\"auto\",  # Let Transformers automatically choose the best device\n    torch_dtype=\"float16\",  # Use half-precision for faster inference\n    trust_remote_code=True\n)\n\n# Predefined conversation responses\nconversations = {\n    \"who built this\": \"This application was built by Adewuyi Ayomide, a passionate Machine Learning Engineer and Computer Science student at the University of Ibadan. He specializes in Natural Language Processing and has a keen interest in making AI more accessible and creative.\",\n    \"who built this application\": \"This application was built by Adewuyi Ayomide, a passionate Machine Learning Engineer and Computer Science student at the University of Ibadan. He specializes in Natural Language Processing and has a keen interest in making AI more accessible and creative.\",\n    \"who built this?\": \"This application was built by Adewuyi Ayomide, a passionate Machine Learning Engineer and Computer Science student at the University of Ibadan. He specializes in Natural Language Processing and has a keen interest in making AI more accessible and creative.\",\n    \"who built this application?\": \"This application was built by Adewuyi Ayomide, a passionate Machine Learning Engineer and Computer Science student at the University of Ibadan. He specializes in Natural Language Processing and has a keen interest in making AI more accessible and creative.\",\n    \"who created you\": \"I was created by Adewuyi Ayomide, a talented Machine Learning Engineer and Computer Science student at the University of Ibadan. He developed me to help people explore the beauty of poetry through AI.\",\n    \"who created you?\": \"I was created by Adewuyi Ayomide, a talented Machine Learning Engineer and Computer Science student at the University of Ibadan. He developed me to help people explore the beauty of poetry through AI.\",\n    \"hey\": \"Hello! ðŸ‘‹ I'm your AI poetry companion. Would you like me to create a poem for you?\",\n    \"hi\": \"Hi there! ðŸ‘‹ Ready to explore the world of poetry together?\",\n    \"hello\": \"Hello! ðŸ‘‹ I'm excited to create some poetry with you today!\",\n    \"help\": \"I can help you create beautiful poems! Just share a topic, emotion, or idea, and I'll craft a unique poem for you. You can also ask me about who created me or just chat casually.\",\n    \"wow\": \"Thank you! I'm glad you're impressed. Would you like me to create another poem for you? Just share any topic that interests you!\",\n    \"amazing\": \"I'm delighted you think so! Would you like to explore more poetry together? Just give me a theme or emotion to work with!\",\n    \"awesome\": \"Thank you for the kind words! I enjoy creating poems. What topic would you like me to write about next?\",\n    \"beautiful\": \"I'm happy you enjoyed it! Poetry is a beautiful way to express emotions. Would you like another poem?\",\n    \"nice\": \"Thank you! I'm here to create more poems whenever you're ready. Just share a topic with me!\",\n    \"great\": \"I'm glad you liked it! Ready for another poetic journey? Just give me a theme to work with!\",\n    \"good\": \"Thank you! I enjoy crafting poems. Would you like to try another topic?\",\n    \"thank you\": \"You're welcome! It's my pleasure to create poems. Feel free to request another one whenever you'd like!\",\n    \"thanks\": \"You're welcome! Ready for another poem whenever you are!\"\n}\n\ndef generate_poem(prompt, history=None):\n    if history is None:\n        history = []  # Initialize history as an empty list if None is passed\n\n    # Check for predefined conversation responses\n    prompt_lower = prompt.strip().lower()\n    if prompt_lower in conversations:\n        response = conversations[prompt_lower]\n        history.append((\"You\", prompt))\n        history.append((\"AI\", response))\n        return history, history\n\n    # Ensure the prompt is not empty\n    if not prompt.strip():\n        return history + [(\"You\", \"Please provide a topic or idea for the poem.\")], history\n\n    try:\n        # Generate the poem using the pipeline with optimized parameters\n        outputs = pipe(prompt, max_new_tokens=500, temperature=0.7, do_sample=True)\n        poem = outputs[0]['generated_text']  # Extract generated text from pipeline output\n    except Exception as e:\n        poem = f\"An error occurred: {e}\"\n\n    # Add the user prompt and the poem response to the history\n    history.append((\"You\", prompt))\n    history.append((\"AI\", poem))\n\n    return history, history\n\n# Create the Gradio interface\ninterface = gr.Interface(\n    fn=generate_poem,\n    inputs=[\"text\", \"state\"],\n    outputs=[\"chatbot\", \"state\"],\n    title=\"Love Poem Generator Chatbot\",\n    description=\"Chat with the AI, and it will generate love poems for you!\"\n)\n\n# Launch the Gradio interface\ninterface.launch(share=True)  # Use share=True to get a public link\n","metadata":{"_uuid":"b2919c8d-dac0-43f3-8511-07a09078c02a","_cell_guid":"3c986f28-8339-4959-938f-b3b423f36982","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}